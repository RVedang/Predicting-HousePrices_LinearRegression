{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sealed-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "velvet-christopher",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reading the data\n",
    "df = pd.read_csv(\"FoDS-Assignment-2.csv\")\n",
    "\n",
    "# shuffle the DataFrame rows\n",
    "df = df.sample(frac = 1)\n",
    "\n",
    "# df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "academic-provider",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sqft_living'] = df.fillna(value = df['sqft_living'].mean())\n",
    "df['floors'] = df.fillna(value = df['floors'].mean())\n",
    "df['sqft_above'] = df.fillna(value = df['sqft_above'].mean())\n",
    "\n",
    "\n",
    "\n",
    "# df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "exclusive-chosen",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "#normalising the data values\n",
    "df = (df - df.min()) / (df.max() - df.min())\n",
    "\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "radio-momentum",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset into training data and testing data\n",
    "splitData = int(0.7*len(X))\n",
    "train_X, test_X, train_y, test_y = X[:splitData], X[splitData:], y[:splitData], y[splitData:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "guided-security",
   "metadata": {},
   "outputs": [],
   "source": [
    "WeightV = np.zeros(14)\n",
    "for n in range(14):\n",
    "    WeightV[n] = np.random.randn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "embedded-spain",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the weights based on the training data\n",
    "def fit(X, Y, iters, learning_rate, c, d):\n",
    "    for n in range(14):\n",
    "        WeightV[n] = np.random.randn()\n",
    "    for itr in range(iters):\n",
    "        sumItrError = 0    \n",
    "        for z in range(len(X)):        # each row in input data\n",
    "            dataP_error = 0            # calculating error in each data point\n",
    "            \n",
    "            for m in range(13):\n",
    "                dataP_error += (c[m] - d[m]) * WeightV[m+1] * X[z][m]    # summation of (w1*x1 + w2*x2 + w3*x3 + w4*x4 ...)\n",
    "                \n",
    "            dataP_error += WeightV[0]\n",
    "            dataP_error -= Y[z]      # (w0 + w1*x1 + w2*x1^2 + w3*x1*x2 + w4*x2^2 ...) - yn\n",
    "\n",
    "            # for each parameter(w0, w1, w2,...)    \n",
    "            for m in range(14):                   \n",
    "                if(m == 0):\n",
    "                    WeightV[m] -= (learning_rate/len(X)) * dataP_error\n",
    "                else:\n",
    "                    WeightV[m] -= (learning_rate/len(X)) * dataP_error * X[z][m-1]   # calculating w0, w1, w2,... for each iteration\n",
    "        \n",
    "            dataP_error = (dataP_error**2)\n",
    "            sumItrError += dataP_error/(2*len(Y))\n",
    "            \n",
    "        sumItrError = (sumItrError)**0.5\n",
    "#         if (itr == iters-1): \n",
    "#             print(\"Minimum training error is \", sumItrError)\n",
    "    return sumItrError    \n",
    "            \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "southwest-insulin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, Y, c, d):\n",
    "    sumItrError = 0\n",
    "    for z in range(len(X)):        # each row in input data\n",
    "        dataP_error = 0            # calculating error in each data point\n",
    "            \n",
    "        for m in range(13):\n",
    "            dataP_error += (c[m] + d[m]) * WeightV[m+1] * X[z][m]    # summation of (w1*x1 + w2*x2 + w3*x3 + w4*x4 ...)\n",
    "        dataP_error += WeightV[0]\n",
    "        \n",
    "        dataP_error -= Y[z]      # (w0 + w1*x1 + w2*x1^2 + w3*x1*x2 + w4*x2^2 ...) - yn\n",
    "        dataP_error = (dataP_error**2)\n",
    "        sumItrError += dataP_error/(2*len(X))\n",
    "            \n",
    "    sumItrError = (sumItrError)**0.5\n",
    "#     print(\"Minimum testing error is \", sumItrError)\n",
    "    return sumItrError \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "characteristic-french",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.037048078832357306\n",
      "0.03753328403891611\n",
      "0.036076437342098616\n",
      "0.03601245629751782\n",
      "0.035804987764602204\n",
      "0.03582159031126961\n",
      "0.03580926897433767\n",
      "0.036096900067102686\n",
      "0.03605366903805068\n",
      "0.03642965417842284\n",
      "0.036580818562904516\n",
      "0.03817135876549594\n",
      "0.05106410516699199\n",
      "Minimum training error is  0.035804987764602204\n",
      "Minimum features needed are  5\n"
     ]
    }
   ],
   "source": [
    "c = np.ones(13)\n",
    "d = np.zeros(13)\n",
    "finalFeatures = np.zeros(13)\n",
    "finalMinE = float('inf')\n",
    "\n",
    "for i in range(13):\n",
    "    minErrorIn_i = float('inf')\n",
    "    for j in range(13):\n",
    "        if(c[j]==0):\n",
    "            continue\n",
    "        d[j] = 1\n",
    "        error_j = fit(train_X, train_y, 500, 1, c, d)\n",
    "        if(error_j < minErrorIn_i):\n",
    "            minErrorIn_i = error_j\n",
    "            minIndex = j\n",
    "        d[j] = 0\n",
    "    c[minIndex] = 0     \n",
    "    if(minErrorIn_i < finalMinE):\n",
    "        finalMinE = minErrorIn_i\n",
    "        finalIndex = i\n",
    "        finalFeatures = c\n",
    "    print(minErrorIn_i) \n",
    "print(\"Minimum training error is \", finalMinE) \n",
    "print(\"Minimum features needed are \", finalIndex+1)     \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acquired-tracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum testing error is  0.047139248526660044\n"
     ]
    }
   ],
   "source": [
    "fit(train_X, train_y, 500, 1, finalFeatures, d)\n",
    "\n",
    "#making predictions on test data\n",
    "testingE = predict(test_X, test_y, finalFeatures, d)\n",
    "print(\"Minimum testing error is \", testingE)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-theology",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
