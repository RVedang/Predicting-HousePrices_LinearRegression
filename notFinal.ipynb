{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sealed-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "velvet-christopher",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bedrooms          0\n",
      "bathrooms         0\n",
      "sqft_living      14\n",
      "sqft_lot          0\n",
      "floors           13\n",
      "waterfront        0\n",
      "view              0\n",
      "condition         0\n",
      "grade             0\n",
      "sqft_above       14\n",
      "sqft_basement     0\n",
      "sqft_living15     0\n",
      "sqft_lot15        0\n",
      "price             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#reading the data\n",
    "df = pd.read_csv(\"FoDS-Assignment-2.csv\")\n",
    "\n",
    "# shuffle the DataFrame rows\n",
    "df = df.sample(frac = 1)\n",
    "\n",
    "df.isnull().sum()\n",
    "\n",
    "# df = (df - df.min()) / (df.max() - df.min())\n",
    "\n",
    "# X = df.iloc[:, :-1].values\n",
    "# y = df.iloc[:, -1].values\n",
    "\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "generous-heater",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bedrooms         0\n",
       "bathrooms        0\n",
       "sqft_living      0\n",
       "sqft_lot         0\n",
       "floors           0\n",
       "waterfront       0\n",
       "view             0\n",
       "condition        0\n",
       "grade            0\n",
       "sqft_above       0\n",
       "sqft_basement    0\n",
       "sqft_living15    0\n",
       "sqft_lot15       0\n",
       "price            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#handling missing values-----dropping rows method\n",
    "\n",
    "df = df.dropna(axis = 0)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "level-humanity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# head = list(df.columns.values)\n",
    "# print(head)\n",
    "# for x in head:\n",
    "#     q90, q10 = np.percentile(df.loc[:, x],[90, 10])\n",
    "#     IQR = q90-q10\n",
    " \n",
    "#     max = q90 + (2 * IQR)\n",
    "#     min = q10 - (2 * IQR)\n",
    " \n",
    "#     df.loc[df[x] < min, x] = np.nan\n",
    "#     df.loc[df[x] > max, x] = np.nan\n",
    "\n",
    "# print(df.isnull().sum())\n",
    "# df = df.dropna(axis = 0)\n",
    "# df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "respective-little",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bedrooms         0\n",
       "bathrooms        0\n",
       "sqft_living      0\n",
       "sqft_lot         0\n",
       "floors           0\n",
       "waterfront       0\n",
       "view             0\n",
       "condition        0\n",
       "grade            0\n",
       "sqft_above       0\n",
       "sqft_basement    0\n",
       "sqft_living15    0\n",
       "sqft_lot15       0\n",
       "price            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "academic-provider",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bedrooms         0\n",
       "bathrooms        0\n",
       "sqft_living      0\n",
       "sqft_lot         0\n",
       "floors           0\n",
       "waterfront       0\n",
       "view             0\n",
       "condition        0\n",
       "grade            0\n",
       "sqft_above       0\n",
       "sqft_basement    0\n",
       "sqft_living15    0\n",
       "sqft_lot15       0\n",
       "price            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# handling missing values-----mean method\n",
    "\n",
    "df['sqft_living'] = df.fillna(value = df['sqft_living'].mean())\n",
    "df['floors'] = df.fillna(value = df['floors'].mean())\n",
    "df['sqft_above'] = df.fillna(value = df['sqft_above'].mean())\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "atlantic-pledge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bedrooms         0\n",
      "bathrooms        0\n",
      "sqft_living      0\n",
      "sqft_lot         0\n",
      "floors           0\n",
      "waterfront       0\n",
      "view             0\n",
      "condition        0\n",
      "grade            0\n",
      "sqft_above       0\n",
      "sqft_basement    0\n",
      "sqft_living15    0\n",
      "sqft_lot15       0\n",
      "price            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())\n",
    "Features_list = [\"bedrooms\", \"bathrooms\", \"sqft_living\", \"sqft_lot\", \"floors\", \"waterfront\", \"view\", \"condition\", \"grade\", \"sqft_above\", \"sqft_basement\", \"sqft_living15\", \"sqft_lot15\"]\n",
    "# df.boxplot(Features_list)\n",
    "# df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "exclusive-chosen",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bedrooms         0\n",
      "bathrooms        0\n",
      "sqft_living      0\n",
      "sqft_lot         0\n",
      "floors           0\n",
      "waterfront       0\n",
      "view             0\n",
      "condition        0\n",
      "grade            0\n",
      "sqft_above       0\n",
      "sqft_basement    0\n",
      "sqft_living15    0\n",
      "sqft_lot15       0\n",
      "price            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Feature Scaling\n",
    "#normalising the data values\n",
    "print(df.isnull().sum())\n",
    "df = (df - df.min()) / (df.max() - df.min())\n",
    "\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "radio-momentum",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset into training data and testing data\n",
    "splitData = int(0.7*len(X))\n",
    "train_X, test_X, train_y, test_y = X[:splitData], X[splitData:], y[:splitData], y[splitData:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eligible-nitrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "WeightV = np.zeros(14)\n",
    "for n in range(14):\n",
    "    WeightV[n] = np.random.randn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "embedded-spain",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the weights based on the training data\n",
    "def fit(X, Y, iters, learning_rate, F_selected, F_trial):\n",
    "    for itr in range(iters):\n",
    "        sumItrError = 0    \n",
    "        for z in range(len(X)):        # each row in input data\n",
    "            dataP_error = 0            # calculating error in each data point\n",
    "            \n",
    "            for m in range(13):\n",
    "                dataP_error += (F_selected[m] + F_trial[m]) * WeightV[m+1] * X[z][m]    # summation of (w1*x1 + w2*x2 + w3*x3 + w4*x4 ...)\n",
    "                \n",
    "            dataP_error += WeightV[0]\n",
    "            dataP_error -= Y[z]      # (w0 + w1*x1 + w2*x1^2 + w3*x1*x2 + w4*x2^2 ...) - yn\n",
    "\n",
    "            # for each parameter(w0, w1, w2,...)    \n",
    "            for m in range(14):                   \n",
    "                if(m == 0):\n",
    "                    WeightV[m] -= (learning_rate/len(X)) * dataP_error\n",
    "                else:\n",
    "                    WeightV[m] -= (learning_rate/len(X)) * dataP_error * X[z][m-1]   # calculating w0, w1, w2,... for each iteration\n",
    "        \n",
    "            dataP_error = (dataP_error**2)\n",
    "            sumItrError += dataP_error/(2*len(Y))\n",
    "            \n",
    "        sumItrError = (sumItrError)**0.5\n",
    "        print(sumItrError)\n",
    "    return sumItrError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "characteristic-french",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, Y, F_selected, F_trial):\n",
    "    sumItrError = 0\n",
    "    for z in range(len(X)):        # each row in input data\n",
    "        dataP_error = 0            # calculating error in each data point\n",
    "            \n",
    "        for m in range(13):\n",
    "            dataP_error += (F_selected[m] + F_trial[m]) * WeightV[m+1] * X[z][m]    # summation of (w1*x1 + w2*x2 + w3*x3 + w4*x4 ...)\n",
    "        dataP_error += WeightV[0]\n",
    "        \n",
    "        dataP_error -= Y[z]      # (w0 + w1*x1 + w2*x1^2 + w3*x1*x2 + w4*x2^2 ...) - yn\n",
    "        dataP_error = (dataP_error**2)\n",
    "        sumItrError += dataP_error/(2*len(X))\n",
    "            \n",
    "    sumItrError = (sumItrError)**0.5\n",
    "    return sumItrError    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acquired-tracy",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\iamth\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-7dfbd9626550>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# df.isnull().sum()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#fitting the training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtrainingE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mF_selected\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mF_trial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Minimum training error is \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainingE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-7dcbd959438d>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(X, Y, iters, learning_rate, F_selected, F_trial)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                 \u001b[0mdataP_error\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mF_selected\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mF_trial\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mWeightV\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m    \u001b[1;31m# summation of (w1*x1 + w2*x2 + w3*x3 + w4*x4 ...)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mdataP_error\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mWeightV\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\iamth\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\iamth\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "F_selected = np.ones(13)\n",
    "F_trial = np.zeros(13)\n",
    "# df.isnull().sum()\n",
    "#fitting the training data\n",
    "trainingE = fit(train_X, train_y, 100, 0.01, F_selected, F_trial)\n",
    "print(\"Minimum training error is \", trainingE)\n",
    "\n",
    "#making predictions on test data\n",
    "testingE = predict(test_X, test_y, F_selected, F_trial)\n",
    "print(\"Minimum testing error is  \", testingE)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-theology",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
